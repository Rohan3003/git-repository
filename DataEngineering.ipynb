{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "\n",
    "    def __init__(self, input_path: str, output_path: str):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def extract_data(self): # dict\n",
    "        # Code to extract data from input_path\n",
    "        pass\n",
    "\n",
    "    def transform_data(self, data: dict):\n",
    "        # Code to trasnform data\n",
    "        pass\n",
    "\n",
    "    def save_data(self, data: dict): # dict\n",
    "        # Code to save transformed data to output_path\n",
    "        pass\n",
    "\n",
    "data_pipeline = DataPipeline(\"input.csv\", \"output.csv\")\n",
    "raw_data = data_pipeline.extract_data()\n",
    "transformed_data = data_pipeline.transform_data(raw_data)\n",
    "data_pipeline.save_data(transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __main__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data ingestion is the process of importing data from various sources into a data processing system. Python is a popular language for data ingestion as it provides a simple and intuitive syntax. Here are 20 important points about data ingestion in Python.\n",
      "\n",
      "1. Python provides a wide range of libraries and tools for importing and processing data.\n",
      "2. The most common format for data ingestion in Python is CSV (Comma Separated Value).\n",
      "3. The pandas library in Python is widely used for data ingestion and analysis.\n",
      "4. The read_csv() function in pandas can be used to import CSV files into Python.\n",
      "5. Other file formats supported by pandas include Excel, SQL, JSON, and HTML.\n",
      "6. The requests library in Python is used to make HTTP requests to web services and APIs for data ingestion.\n",
      "7. The Beautiful Soup library in Python is used to extract data from web pages.\n",
      "8. Data ingestion from NoSQL databases like MongoDB, Cassandra, and HBase can be done using Python libraries like pymongo.\n",
      "9. The pysftp library in Python is used to connect to and import data from remote servers.\n",
      "10. The glob module in Python is used to search and import data from multiple files.\n",
      "11. The os module in Python is used to navigate and manipulate directories and file systems for data ingestion.\n",
      "12. The Gzip library in Python is used to import and decompress gzip files.\n",
      "13. The bz2 library in Python is used to import and decompress bz2 compressed files.\n",
      "14. The zipfile module in Python is used to import and unzip zip files.\n",
      "15. The tarfile library in Python is used to import and extract data from tar files.\n",
      "16. The PyPDF2 library in Python is used to import data from PDF files.\n",
      "17. The pytesseract library in Python is used for optical character recognition (OCR) to import data from images.\n",
      "18. The SpeechRecognition library in Python is used to import data from audio files.\n",
      "19. The PyAudio library in Python is used to record and import data from live audio streams.\n",
      "20. Python's multiprocessing library can be used to parallelize data ingestion for efficiency and faster processing.\n",
      "\n",
      "In conclusion, Python with its vast libraries and tools provides an efficient, flexible, and intuitive environment for data ingestion from various sources.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "# from apikey import APIKEY\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "output = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\":\"user\", \"content\":\"Write a article on data ingestion in python in 20 lines\"}]\n",
    ")\n",
    "\n",
    "# Print out the whole output directory\n",
    "# print(output)\n",
    "\n",
    "# Get the output text only\n",
    "print(output['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
