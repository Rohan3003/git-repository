{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fill in the `...` below so that the function `correct_` applies\n",
    "  - The `parse_stocks` function to `df` when `_type == \"stocks\"`\n",
    "  - The `parse_transports` function to `df` when `_type == \"transports\"`\n",
    "  - The `parse_releases` function otherwise\n",
    " \n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_(df: DataFrame, _type: str) -> DataFrame:\n",
    "    choices = {\n",
    "        \"stocks\": parse_stocks,\n",
    "        \"transports\": parse_transports\n",
    "    }\n",
    "    if _type == 'parse_stocks':\n",
    "        df.apply(choices[\"stocks\"])\n",
    "    elif _type == 'parse_transports':\n",
    "        df.apply(choices[\"parse_transports\"])\n",
    "    else:\n",
    "        parse_releases(df)\n",
    "    return parse(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finish this code to get, **within** a subject, the best student in a subject. Multiple marks need to be averaged!\n",
    "```python\n",
    "df = spark.createDataFrame(\n",
    "  [\n",
    "      [\"student_1\", \"math\", 78],\n",
    "      [\"student_1\", \"math\", 53],\n",
    "      [\"student_2\", \"math\", 55],\n",
    "      [\"student_1\", \"english\", 40],\n",
    "      [\"student_2\", \"english\", 53],\n",
    "      [\"student_2\", \"english\", 55],\n",
    "      [\"student_3\", \"english\", 85],\n",
    "      [\"student_3\", \"math\", 59],\n",
    "  ],\n",
    "    schema=[\"student\", \"subject\", \"mark\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.function import avg\n",
    "df.groupBy('subject').agg(avg('mark')).alias('avg_marks').orderBy('avg_marks',desc).limit(1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
